#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
·ª®ng d·ª•ng web ƒë∆°n gi·∫£n ƒë·ªÉ demo giao di·ªán nh·∫≠n di·ªán khu√¥n m·∫∑t
Simple Web App for Face Recognition UI Demo
"""

import os
import json
import base64
import gc
from datetime import datetime

# Optional imports
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("‚ö†Ô∏è psutil kh√¥ng c√≥ s·∫µn, b·ªè qua monitoring hi·ªáu su·∫•t")
from flask import Flask, render_template, request, jsonify, redirect, url_for, flash
from werkzeug.utils import secure_filename
import cv2
import numpy as np

# Import face_recognition n·∫øu c√≥ s·∫µn, n·∫øu kh√¥ng th√¨ fallback v·ªÅ OpenCV
try:
    import face_recognition  # type: ignore
    FACE_RECOGNITION_AVAILABLE = True
    print("‚úì S·ª≠ d·ª•ng th∆∞ vi·ªán face_recognition cho ƒë·ªô ch√≠nh x√°c cao")
except ImportError:
    FACE_RECOGNITION_AVAILABLE = False
    print("‚ö† Kh√¥ng c√≥ face_recognition, s·ª≠ d·ª•ng OpenCV c∆° b·∫£n")

app = Flask(__name__)
app.secret_key = 'face_recognition_demo_key_2024'

# C·∫•u h√¨nh
UPLOAD_FOLDER = 'uploads'
KNOWN_FACES_FOLDER = 'known_faces'
ALLOWED_IMAGE_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}
ALLOWED_VIDEO_EXTENSIONS = {'mp4', 'avi', 'mov', 'mkv', 'webm'}
ALLOWED_EXTENSIONS = ALLOWED_IMAGE_EXTENSIONS | ALLOWED_VIDEO_EXTENSIONS

# T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(KNOWN_FACES_FOLDER, exist_ok=True)

# C∆° s·ªü d·ªØ li·ªáu khu√¥n m·∫∑t ƒë√£ bi·∫øt (ƒë∆°n gi·∫£n)
KNOWN_FACES_DB = {}
KNOWN_FACE_ENCODINGS = {}  # L∆∞u tr·ªØ encoding c·ªßa khu√¥n m·∫∑t ƒë√£ bi·∫øt

def allowed_file(filename):
    """Ki·ªÉm tra file c√≥ ƒë∆∞·ª£c ph√©p upload kh√¥ng"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def is_image_file(filename):
    """Ki·ªÉm tra file c√≥ ph·∫£i ·∫£nh kh√¥ng"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_IMAGE_EXTENSIONS

def is_video_file(filename):
    """Ki·ªÉm tra file c√≥ ph·∫£i video kh√¥ng"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_VIDEO_EXTENSIONS

def get_memory_usage():
    """L·∫•y th√¥ng tin s·ª≠ d·ª•ng b·ªô nh·ªõ"""
    if not PSUTIL_AVAILABLE:
        return {'rss': 0, 'vms': 0, 'percent': 0}

    try:
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        return {
            'rss': memory_info.rss / 1024 / 1024,  # MB
            'vms': memory_info.vms / 1024 / 1024,  # MB
            'percent': process.memory_percent()
        }
    except:
        return {'rss': 0, 'vms': 0, 'percent': 0}

def optimize_image_for_processing(image, max_size=1024):
    """T·ªëi ∆∞u h√≥a ·∫£nh ƒë·ªÉ x·ª≠ l√Ω nhanh h∆°n"""
    try:
        height, width = image.shape[:2]

        # Resize n·∫øu ·∫£nh qu√° l·ªõn
        if max(height, width) > max_size:
            scale = max_size / max(height, width)
            new_width = int(width * scale)
            new_height = int(height * scale)
            image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)

        return image
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói t·ªëi ∆∞u h√≥a ·∫£nh: {e}")
        return image

def cleanup_temp_files():
    """D·ªçn d·∫πp file t·∫°m th·ªùi c≈©"""
    try:
        current_time = datetime.now()
        cleanup_count = 0

        for filename in os.listdir(UPLOAD_FOLDER):
            filepath = os.path.join(UPLOAD_FOLDER, filename)
            if os.path.isfile(filepath):
                # Ki·ªÉm tra file c≈© (h∆°n 1 gi·ªù)
                file_age = current_time - datetime.fromtimestamp(os.path.getmtime(filepath))
                if file_age.total_seconds() > 3600:  # 1 hour
                    try:
                        os.remove(filepath)
                        cleanup_count += 1
                        print(f"üóëÔ∏è ƒê√£ x√≥a file t·∫°m: {filename}")
                    except:
                        pass

        if cleanup_count > 0:
            print(f"‚úÖ ƒê√£ d·ªçn d·∫πp {cleanup_count} file t·∫°m th·ªùi")

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói d·ªçn d·∫πp file t·∫°m: {e}")

def performance_monitor(func):
    """Decorator ƒë·ªÉ theo d√µi hi·ªáu su·∫•t"""
    def wrapper(*args, **kwargs):
        start_time = datetime.now()
        start_memory = get_memory_usage()

        try:
            result = func(*args, **kwargs)
            return result
        finally:
            end_time = datetime.now()
            end_memory = get_memory_usage()

            duration = (end_time - start_time).total_seconds()
            memory_diff = end_memory['rss'] - start_memory['rss']

            print(f"üìä {func.__name__}: {duration:.2f}s, Memory: {memory_diff:+.1f}MB")

            # Force garbage collection n·∫øu s·ª≠ d·ª•ng nhi·ªÅu b·ªô nh·ªõ
            if memory_diff > 50:  # > 50MB
                gc.collect()

    return wrapper

@performance_monitor
def process_video_for_faces(video_path, max_frames=50, skip_frames=30):
    """X·ª≠ l√Ω video ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t, tr·∫£ v·ªÅ danh s√°ch frame c√≥ khu√¥n m·∫∑t"""
    try:
        print(f"\nüé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video: {video_path}")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("‚ùå Kh√¥ng th·ªÉ m·ªü video")
            return []

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        print(f"üìä Video info: {total_frames} frames, {fps:.1f} FPS")

        # T√≠nh to√°n frame sampling
        frame_interval = max(1, total_frames // max_frames)
        if skip_frames > 0:
            frame_interval = max(frame_interval, skip_frames)

        print(f"üîç X·ª≠ l√Ω m·ªói {frame_interval} frame ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t")

        face_frames = []
        frame_count = 0
        processed_count = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1

            # Ch·ªâ x·ª≠ l√Ω frame theo interval
            if frame_count % frame_interval != 0:
                continue

            processed_count += 1

            try:
                # Ph√°t hi·ªán khu√¥n m·∫∑t trong frame
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

                # S·ª≠ d·ª•ng Haar Cascade v·ªõi tham s·ªë t·ªëi ∆∞u cho video
                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

                faces = face_cascade.detectMultiScale(
                    gray,
                    scaleFactor=1.1,
                    minNeighbors=5,
                    minSize=(30, 30),
                    maxSize=(200, 200)
                )

                if len(faces) > 0:
                    # L∆∞u frame c√≥ khu√¥n m·∫∑t
                    face_frames.append({
                        'frame_number': frame_count,
                        'timestamp': frame_count / fps if fps > 0 else 0,
                        'faces': faces,
                        'frame': frame.copy()
                    })

                    print(f"‚úì Frame {frame_count}: T√¨m th·∫•y {len(faces)} khu√¥n m·∫∑t")

                    # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng frame c√≥ khu√¥n m·∫∑t ƒë·ªÉ tr√°nh qu√° t·∫£i
                    if len(face_frames) >= 20:  # T·ªëi ƒëa 20 frame c√≥ khu√¥n m·∫∑t
                        print("üéØ ƒê√£ ƒë·∫°t gi·ªõi h·∫°n frame c√≥ khu√¥n m·∫∑t, d·ª´ng x·ª≠ l√Ω")
                        break

            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω frame {frame_count}: {e}")
                continue

            # Hi·ªÉn th·ªã ti·∫øn tr√¨nh
            if processed_count % 10 == 0:
                print(f"üìà ƒê√£ x·ª≠ l√Ω {processed_count} frames, t√¨m th·∫•y {len(face_frames)} frame c√≥ khu√¥n m·∫∑t")

        cap.release()

        print(f"‚úÖ Ho√†n th√†nh x·ª≠ l√Ω video: {len(face_frames)} frame c√≥ khu√¥n m·∫∑t t·ª´ {processed_count} frames ƒë√£ x·ª≠ l√Ω")
        return face_frames

    except Exception as e:
        print(f"‚ùå L·ªói x·ª≠ l√Ω video: {e}")
        return []

def batch_process_images(image_paths, known_faces_db=None):
    """X·ª≠ l√Ω batch nhi·ªÅu ·∫£nh c√πng l√∫c"""
    if known_faces_db is None:
        known_faces_db = KNOWN_FACES_DB

    results = []
    total_faces_found = 0

    print(f"\nüîÑ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω batch {len(image_paths)} ·∫£nh...")

    for i, image_path in enumerate(image_paths):
        print(f"\n--- X·ª≠ l√Ω ·∫£nh {i+1}/{len(image_paths)}: {os.path.basename(image_path)} ---")

        try:
            # Nh·∫≠n di·ªán khu√¥n m·∫∑t trong ·∫£nh
            faces, face_count = detect_faces_advanced(image_path, known_faces_db)
            total_faces_found += face_count

            # Th√™m th√¥ng tin file v√†o k·∫øt qu·∫£
            image_result = {
                'file_path': image_path,
                'file_name': os.path.basename(image_path),
                'faces': faces,
                'face_count': face_count,
                'processed_at': datetime.now().isoformat(),
                'index': i
            }

            results.append(image_result)

            recognized_faces = len([f for f in faces if f.get('best_match')])
            print(f"‚úÖ {os.path.basename(image_path)}: {face_count} khu√¥n m·∫∑t, {recognized_faces} ƒë∆∞·ª£c nh·∫≠n di·ªán")

        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω {os.path.basename(image_path)}: {e}")
            results.append({
                'file_path': image_path,
                'file_name': os.path.basename(image_path),
                'faces': [],
                'face_count': 0,
                'error': str(e),
                'processed_at': datetime.now().isoformat(),
                'index': i
            })

    print(f"\nüìã K·∫æT QU·∫¢ BATCH:")
    print(f"  - T·ªïng ·∫£nh x·ª≠ l√Ω: {len(image_paths)}")
    print(f"  - T·ªïng khu√¥n m·∫∑t ph√°t hi·ªán: {total_faces_found}")
    print(f"  - ·∫¢nh x·ª≠ l√Ω th√†nh c√¥ng: {len([r for r in results if 'error' not in r])}")
    print(f"  - ·∫¢nh x·ª≠ l√Ω th·∫•t b·∫°i: {len([r for r in results if 'error' in r])}")

    return results, total_faces_found

def batch_process_videos(video_paths, known_faces_db=None):
    """X·ª≠ l√Ω batch nhi·ªÅu video c√πng l√∫c"""
    if known_faces_db is None:
        known_faces_db = KNOWN_FACES_DB

    results = []
    total_faces_found = 0

    print(f"\nüé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω batch {len(video_paths)} video...")

    for i, video_path in enumerate(video_paths):
        print(f"\n--- X·ª≠ l√Ω video {i+1}/{len(video_paths)}: {os.path.basename(video_path)} ---")

        try:
            # Nh·∫≠n di·ªán khu√¥n m·∫∑t trong video
            faces, face_count = recognize_faces_in_video(video_path, known_faces_db)
            total_faces_found += face_count

            # Th·ªëng k√™ cho video n√†y
            recognized_faces = len([f for f in faces if f.get('best_match')])
            unique_persons = len(set([f['best_match'][0] for f in faces if f.get('best_match')]))

            # Th√™m th√¥ng tin file v√†o k·∫øt qu·∫£
            video_result = {
                'file_path': video_path,
                'file_name': os.path.basename(video_path),
                'faces': faces,
                'face_count': face_count,
                'recognized_faces': recognized_faces,
                'unique_persons': unique_persons,
                'processed_at': datetime.now().isoformat(),
                'index': i,
                'media_type': 'video'
            }

            results.append(video_result)

            print(f"‚úÖ {os.path.basename(video_path)}: {face_count} khu√¥n m·∫∑t, {recognized_faces} ƒë∆∞·ª£c nh·∫≠n di·ªán, {unique_persons} ng∆∞·ªùi duy nh·∫•t")

        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω {os.path.basename(video_path)}: {e}")
            results.append({
                'file_path': video_path,
                'file_name': os.path.basename(video_path),
                'faces': [],
                'face_count': 0,
                'error': str(e),
                'processed_at': datetime.now().isoformat(),
                'index': i,
                'media_type': 'video'
            })

    print(f"\nüìã K·∫æT QU·∫¢ BATCH VIDEO:")
    print(f"  - T·ªïng video x·ª≠ l√Ω: {len(video_paths)}")
    print(f"  - T·ªïng khu√¥n m·∫∑t ph√°t hi·ªán: {total_faces_found}")
    print(f"  - Video x·ª≠ l√Ω th√†nh c√¥ng: {len([r for r in results if 'error' not in r])}")
    print(f"  - Video x·ª≠ l√Ω th·∫•t b·∫°i: {len([r for r in results if 'error' in r])}")

    return results, total_faces_found

def recognize_faces_in_video(video_path, known_faces_db=None):
    """Nh·∫≠n di·ªán khu√¥n m·∫∑t trong video"""
    try:
        print(f"\nüé¨ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán khu√¥n m·∫∑t trong video: {video_path}")

        # X·ª≠ l√Ω video ƒë·ªÉ l·∫•y frames c√≥ khu√¥n m·∫∑t
        face_frames = process_video_for_faces(video_path)

        if not face_frames:
            return [], 0

        # S·ª≠ d·ª•ng known_faces_db ƒë∆∞·ª£c truy·ªÅn v√†o ho·∫∑c KNOWN_FACES_DB global
        if known_faces_db is None:
            known_faces_db = KNOWN_FACES_DB

        all_results = []
        total_faces_found = 0

        print(f"\nüîç B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán {len(face_frames)} frame c√≥ khu√¥n m·∫∑t...")

        for i, frame_data in enumerate(face_frames):
            print(f"\n--- X·ª≠ l√Ω Frame {i+1}/{len(face_frames)} (Frame #{frame_data['frame_number']}) ---")

            frame = frame_data['frame']
            frame_faces = frame_data['faces']
            frame_results = []

            # X·ª≠ l√Ω t·ª´ng khu√¥n m·∫∑t trong frame
            for j, (x, y, w, h) in enumerate(frame_faces):
                print(f"  üë§ X·ª≠ l√Ω khu√¥n m·∫∑t {j+1} trong frame {frame_data['frame_number']}")

                total_faces_found += 1

                # T·∫°o ·∫£nh khu√¥n m·∫∑t
                face_roi = frame[y:y+h, x:x+w]

                # L∆∞u frame t·∫°m th·ªùi ƒë·ªÉ x·ª≠ l√Ω
                temp_frame_path = f"temp_frame_{i}_{j}.jpg"
                cv2.imwrite(temp_frame_path, face_roi)

                try:
                    # Nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ ·∫£nh ƒë√£ c·∫Øt
                    results, _ = detect_faces_advanced(temp_frame_path, known_faces_db)

                    if results:
                        # Th√™m th√¥ng tin frame v√†o k·∫øt qu·∫£
                        result = results[0].copy()
                        result['frame_number'] = frame_data['frame_number']
                        result['timestamp'] = frame_data['timestamp']
                        result['frame_index'] = i
                        result['face_index_in_frame'] = j

                        # ƒêi·ªÅu ch·ªânh t·ªça ƒë·ªô v·ªÅ frame g·ªëc
                        result['location']['top'] += y
                        result['location']['bottom'] += y
                        result['location']['left'] += x
                        result['location']['right'] += x

                        frame_results.append(result)

                        if result.get('best_match'):
                            name, similarity = result['best_match']
                            print(f"    ‚úÖ Nh·∫≠n di·ªán: {name} ({similarity:.4f}) t·∫°i frame {frame_data['frame_number']}")
                        else:
                            print(f"    ‚ùì Kh√¥ng x√°c ƒë·ªãnh t·∫°i frame {frame_data['frame_number']}")
                    else:
                        # T·∫°o k·∫øt qu·∫£ tr·ªëng n·∫øu kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c
                        frame_results.append({
                            'location': {
                                'top': y, 'left': x,
                                'bottom': y+h, 'right': x+w
                            },
                            'matches': [],
                            'best_match': None,
                            'frame_number': frame_data['frame_number'],
                            'timestamp': frame_data['timestamp'],
                            'frame_index': i,
                            'face_index_in_frame': j
                        })
                        print(f"    ‚ùå Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t t·∫°i frame {frame_data['frame_number']}")

                except Exception as e:
                    print(f"    ‚ö†Ô∏è L·ªói nh·∫≠n di·ªán khu√¥n m·∫∑t {j+1}: {e}")
                finally:
                    # X√≥a file t·∫°m
                    if os.path.exists(temp_frame_path):
                        os.remove(temp_frame_path)

            all_results.extend(frame_results)

        # S·∫Øp x·∫øp theo th·ªùi gian xu·∫•t hi·ªán
        all_results.sort(key=lambda x: x['timestamp'])

        recognized_faces = len([r for r in all_results if r.get('best_match')])
        unrecognized_faces = total_faces_found - recognized_faces

        print(f"\nüìã K·∫æT QU·∫¢ NH·∫¨N DI·ªÜN VIDEO:")
        print(f"  - T·ªïng khu√¥n m·∫∑t ph√°t hi·ªán: {total_faces_found}")
        print(f"  - Khu√¥n m·∫∑t ƒë∆∞·ª£c nh·∫≠n di·ªán: {recognized_faces}")
        print(f"  - Khu√¥n m·∫∑t kh√¥ng x√°c ƒë·ªãnh: {unrecognized_faces}")
        print(f"  - S·ªë frame c√≥ khu√¥n m·∫∑t: {len(face_frames)}")

        return all_results, total_faces_found

    except Exception as e:
        print(f"‚ùå L·ªói nh·∫≠n di·ªán video: {e}")
        import traceback
        traceback.print_exc()
        return [], 0

def load_known_faces():
    """Load c∆° s·ªü d·ªØ li·ªáu khu√¥n m·∫∑t ƒë√£ bi·∫øt"""
    # Th·ª≠ load t·ª´ file JSON ƒë·ªÉ l∆∞u tr·ªØ b·ªÅn v·ªØng
    json_path = os.path.join(KNOWN_FACES_FOLDER, 'known_faces.json')
    if os.path.exists(json_path):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                global KNOWN_FACES_DB
                KNOWN_FACES_DB = data
                
                # T·∫°o encoding cho c√°c khu√¥n m·∫∑t ƒë√£ bi·∫øt
                if FACE_RECOGNITION_AVAILABLE:
                    create_face_encodings(data)
                
                return data
        except Exception as e:
            print(f"L·ªói khi load database: {e}")
    
    return KNOWN_FACES_DB

def extract_face_metadata(image_path):
    """Tr√≠ch xu·∫•t metadata t·ª´ khu√¥n m·∫∑t trong ·∫£nh"""
    metadata = {
        'face_count': 0,
        'faces': [],
        'quality_score': 0.0,
        'brightness': 0.0,
        'contrast': 0.0,
        'blur_score': 0.0
    }

    try:
        if FACE_RECOGNITION_AVAILABLE:
            # S·ª≠ d·ª•ng face_recognition ƒë·ªÉ l·∫•y th√¥ng tin chi ti·∫øt
            image = face_recognition.load_image_file(image_path)
            face_locations = face_recognition.face_locations(image)

            metadata['face_count'] = len(face_locations)

            if len(face_locations) > 0:
                # Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t
                pil_image = cv2.imread(image_path)
                if pil_image is not None:
                    gray = cv2.cvtColor(pil_image, cv2.COLOR_BGR2GRAY)

                    for i, (top, right, bottom, left) in enumerate(face_locations):
                        face_roi = gray[top:bottom, left:right]

                        if face_roi.size > 0:
                            # T√≠nh c√°c ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng
                            brightness = np.mean(face_roi) / 255.0
                            contrast = np.std(face_roi) / 255.0
                            blur_score = cv2.Laplacian(face_roi, cv2.CV_64F).var()

                            face_info = {
                                'index': i,
                                'location': {'top': top, 'right': right, 'bottom': bottom, 'left': left},
                                'brightness': float(brightness),
                                'contrast': float(contrast),
                                'blur_score': float(blur_score),
                                'quality_score': min(1.0, (brightness * 0.3 + contrast * 0.4 + min(blur_score/500, 1.0) * 0.3))
                            }

                            metadata['faces'].append(face_info)

                    # T√≠nh ch·∫•t l∆∞·ª£ng t·ªïng th·ªÉ (l·∫•y khu√¥n m·∫∑t t·ªët nh·∫•t)
                    if metadata['faces']:
                        best_face = max(metadata['faces'], key=lambda x: x['quality_score'])
                        metadata.update({
                            'quality_score': best_face['quality_score'],
                            'brightness': best_face['brightness'],
                            'contrast': best_face['contrast'],
                            'blur_score': best_face['blur_score']
                        })
        else:
            # Fallback to OpenCV
            image = cv2.imread(image_path)
            if image is not None:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(50, 50))

                metadata['face_count'] = len(faces)

                if len(faces) > 0:
                    # Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t t·ªët nh·∫•t
                    best_quality = 0.0
                    best_metrics = {'brightness': 0.0, 'contrast': 0.0, 'blur_score': 0.0}

                    for (x, y, w, h) in faces:
                        face_roi = gray[y:y+h, x:x+w]
                        if face_roi.size > 0:
                            brightness = np.mean(face_roi) / 255.0
                            contrast = np.std(face_roi) / 255.0
                            blur_score = cv2.Laplacian(face_roi, cv2.CV_64F).var()

                            quality = min(1.0, (brightness * 0.3 + contrast * 0.4 + min(blur_score/300, 1.0) * 0.3))

                            if quality > best_quality:
                                best_quality = quality
                                best_metrics = {
                                    'brightness': float(brightness),
                                    'contrast': float(contrast),
                                    'blur_score': float(blur_score)
                                }

                    metadata.update({
                        'quality_score': best_quality,
                        'brightness': best_metrics['brightness'],
                        'contrast': best_metrics['contrast'],
                        'blur_score': best_metrics['blur_score']
                    })

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi tr√≠ch xu·∫•t metadata: {e}")

    return metadata

def create_face_encodings(known_faces):
    """T·∫°o encoding cho c√°c khu√¥n m·∫∑t ƒë√£ bi·∫øt"""
    global KNOWN_FACE_ENCODINGS
    KNOWN_FACE_ENCODINGS = {}

    print("üîÑ ƒêang t·∫°o encoding cho c√°c khu√¥n m·∫∑t ƒë√£ bi·∫øt...")

    for name, face_data in known_faces.items():
        if 'image_path' in face_data and os.path.exists(face_data['image_path']):
            try:
                # Load ·∫£nh v√† t·∫°o encoding
                image = face_recognition.load_image_file(face_data['image_path'])
                face_encodings = face_recognition.face_encodings(image)

                if len(face_encodings) > 0:
                    # L·∫•y encoding ƒë·∫ßu ti√™n (khu√¥n m·∫∑t ch√≠nh)
                    KNOWN_FACE_ENCODINGS[name] = face_encodings[0]

                    # C·∫≠p nh·∫≠t metadata n·∫øu ch∆∞a c√≥
                    if 'metadata' not in face_data:
                        metadata = extract_face_metadata(face_data['image_path'])
                        face_data['metadata'] = metadata
                        print(f"‚úì ƒê√£ c·∫≠p nh·∫≠t metadata cho {name}")

                    print(f"‚úì ƒê√£ t·∫°o encoding cho {name}")
                else:
                    print(f"‚ö† Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh c·ªßa {name}")

            except Exception as e:
                print(f"‚ùå L·ªói khi t·∫°o encoding cho {name}: {e}")

    print(f"‚úÖ Ho√†n th√†nh t·∫°o encoding cho {len(KNOWN_FACE_ENCODINGS)} khu√¥n m·∫∑t")

def save_known_faces(known_faces):
    """L∆∞u c∆° s·ªü d·ªØ li·ªáu khu√¥n m·∫∑t"""
    global KNOWN_FACES_DB
    KNOWN_FACES_DB = known_faces
    
    # L∆∞u v√†o file JSON ƒë·ªÉ b·ªÅn v·ªØng
    json_path = os.path.join(KNOWN_FACES_FOLDER, 'known_faces.json')
    try:
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(known_faces, f, ensure_ascii=False, indent=2)
        
        # T·∫°o l·∫°i encoding n·∫øu c√≥ thay ƒë·ªïi
        if FACE_RECOGNITION_AVAILABLE:
            create_face_encodings(known_faces)
            
    except Exception as e:
        print(f"L·ªói khi l∆∞u database: {e}")

@performance_monitor
def detect_faces_advanced(image_path, known_faces_db=None):
    """
    NH·∫¨N DI·ªÜN KHU√îN M·∫∂T THEO NGUY√äN L√ù 5 B∆Ø·ªöC

    B∆∞·ªõc 1: PH√ÅT HI·ªÜN (Detection)
    - S·ª≠ d·ª•ng th·ªã gi√°c m√°y t√≠nh ƒë·ªÉ t√¨m ki·∫øm v√† x√°c ƒë·ªãnh v·ªã tr√≠ khu√¥n m·∫∑t trong ·∫£nh
    - Ph√°t hi·ªán ƒë∆∞·ª£c nhi·ªÅu khu√¥n m·∫∑t c√πng l√∫c t·ª´ c√°c g√≥c ƒë·ªô kh√°c nhau

    B∆∞·ªõc 2: PH√ÇN T√çCH (Analysis)
    - Ph√¢n t√≠ch chi ti·∫øt c√°c ƒë·∫∑c ƒëi·ªÉm khu√¥n m·∫∑t:
      * Kho·∫£ng c√°ch gi·ªØa hai m·∫Øt
      * Kho·∫£ng c√°ch t·ª´ m≈©i ƒë·∫øn mi·ªáng
      * Kho·∫£ng c√°ch t·ª´ tr√°n ƒë·∫øn c·∫±m
      * H√¨nh d·∫°ng g√≤ m√°, ƒë·ªô s√¢u h·ªëc m·∫Øt
      * ƒê∆∞·ªùng vi·ªÅn m√¥i, tai, c·∫±m
    - T·∫°o faceprint (d·∫•u v√¢n tay k·ªπ thu·∫≠t s·ªë) duy nh·∫•t cho m·ªói ng∆∞·ªùi

    B∆∞·ªõc 3: CHUY·ªÇN ƒê·ªîI D·ªÆ LI·ªÜU (Data Conversion)
    - M√£ h√≥a d·ªØ li·ªáu khu√¥n m·∫∑t th√†nh c√°c m√£ s·ªë ƒë·∫∑c bi·ªát
    - T·∫°o vector ƒë·∫∑c tr∆∞ng cho vi·ªác l∆∞u tr·ªØ v√† x·ª≠ l√Ω nhanh ch√≥ng

    B∆∞·ªõc 4: SO KH·ªöP D·ªÆ LI·ªÜU (Matching)
    - So s√°nh faceprint v·ªõi d·ªØ li·ªáu trong c∆° s·ªü d·ªØ li·ªáu
    - S·ª≠ d·ª•ng thu·∫≠t to√°n h·ªçc m√°y v√† AI ƒë·ªÉ t√≠nh ƒë·ªô tr√πng kh·ªõp

    B∆∞·ªõc 5: X√ÅC NH·∫¨N DANH T√çNH (Verification)
    - X√°c nh·∫≠n ho·∫∑c t·ª´ ch·ªëi danh t√≠nh d·ª±a tr√™n ƒë·ªô tr√πng kh·ªõp
    - Tr·∫£ v·ªÅ k·∫øt qu·∫£ v·ªõi ƒë·ªô tin c·∫≠y
    """
    if not FACE_RECOGNITION_AVAILABLE:
        print("‚ö† face_recognition kh√¥ng kh·∫£ d·ª•ng, fallback v·ªÅ OpenCV")
        return detect_faces_simple(image_path, known_faces_db)

    try:
        print(f"\nüîç [B∆Ø·ªöC 1: PH√ÅT HI·ªÜN] B·∫Øt ƒë·∫ßu qu√©t khu√¥n m·∫∑t t·ª´: {image_path}")

        # ===== B∆Ø·ªöC 1: PH√ÅT HI·ªÜN =====
        # Load v√† t·ªëi ∆∞u h√≥a ·∫£nh ƒë·ªÉ x·ª≠ l√Ω nhanh h∆°n
        image = face_recognition.load_image_file(image_path)

        # T·ªëi ∆∞u h√≥a k√≠ch th∆∞·ªõc ·∫£nh
        if image.shape[0] > 1200 or image.shape[1] > 1200:
            scale = min(1200 / image.shape[0], 1200 / image.shape[1])
            new_width = int(image.shape[1] * scale)
            new_height = int(image.shape[0] * scale)
            image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)

        # Ph√°t hi·ªán v·ªã tr√≠ khu√¥n m·∫∑t trong ·∫£nh
        face_locations = face_recognition.face_locations(image)
        print(f"üìç Ph√°t hi·ªán {len(face_locations)} khu√¥n m·∫∑t trong ·∫£nh")

        if len(face_locations) == 0:
            print("‚ùå [K·∫æT QU·∫¢] Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t n√†o trong ·∫£nh")
            return [], 0

        print(f"\nüß† [B∆Ø·ªöC 2: PH√ÇN T√çCH] Ph√¢n t√≠ch ƒë·∫∑c ƒëi·ªÉm khu√¥n m·∫∑t...")

        # ===== B∆Ø·ªöC 2: PH√ÇN T√çCH =====
        # T·∫°o face encoding (faceprint) cho t·ª´ng khu√¥n m·∫∑t
        face_encodings = face_recognition.face_encodings(image, face_locations)
        print(f"üîê ƒê√£ t·∫°o {len(face_encodings)} faceprint k·ªπ thu·∫≠t s·ªë")

        # ===== B∆Ø·ªöC 3: CHUY·ªÇN ƒê·ªîI D·ªÆ LI·ªÜU =====
        # D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi th√†nh vector ƒë·∫∑c tr∆∞ng trong face_encodings

        # S·ª≠ d·ª•ng known_faces_db ƒë∆∞·ª£c truy·ªÅn v√†o ho·∫∑c KNOWN_FACES_DB global
        if known_faces_db is None:
            # Ch·∫ø ƒë·ªô ch·ªâ ph√°t hi·ªán khu√¥n m·∫∑t (kh√¥ng so s√°nh) - d√πng khi ƒëƒÉng k√Ω
            print(f"\nüîç [CH·ªà PH√ÅT HI·ªÜN] Kh√¥ng so s√°nh v·ªõi database - ch·∫ø ƒë·ªô ƒëƒÉng k√Ω khu√¥n m·∫∑t m·ªõi")
            
            results = []
            for i, face_location in enumerate(face_locations):
                top, right, bottom, left = face_location
                
                result = {
                    'location': {
                        'top': int(top),
                        'right': int(right),
                        'bottom': int(bottom),
                        'left': int(left)
                    },
                    'matches': [],
                    'best_match': None,
                    'face_index': i + 1
                }
                results.append(result)
                print(f"‚úì Ph√°t hi·ªán khu√¥n m·∫∑t {i+1} t·∫°i v·ªã tr√≠ ({top}, {right}, {bottom}, {left})")
            
            return results, len(face_locations)
        
        known_faces_db = KNOWN_FACES_DB

        print(f"\nüîç [B∆Ø·ªöC 4: SO KH·ªöP] So s√°nh v·ªõi {len(KNOWN_FACE_ENCODINGS)} khu√¥n m·∫∑t trong database...")

        # ===== B∆Ø·ªöC 4: SO KH·ªöP D·ªÆ LI·ªÜU =====
        results = []

        for i, (face_location, face_encoding) in enumerate(zip(face_locations, face_encodings)):
            print(f"\n--- Ph√¢n t√≠ch khu√¥n m·∫∑t {i+1} ---")

            # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô khu√¥n m·∫∑t
            top, right, bottom, left = face_location

            # So s√°nh faceprint v·ªõi database
            matches = []
            best_match = None
            best_similarity = 0.0

            for name, known_encoding in KNOWN_FACE_ENCODINGS.items():
                try:
                    # T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa 2 faceprint
                    face_distance = face_recognition.face_distance([known_encoding], face_encoding)[0]

                    # Chuy·ªÉn ƒë·ªïi th√†nh ƒë·ªô t∆∞∆°ng ƒë·ªìng (0-1, c√†ng cao c√†ng gi·ªëng)
                    similarity = 1.0 - face_distance

                    print(f"  üìä So s√°nh v·ªõi {name}: distance={face_distance:.4f}, similarity={similarity:.4f} ({similarity:.1%})")

                    # Ng∆∞·ª°ng nh·∫≠n d·∫°ng v·ªõi nhi·ªÅu m·ª©c ƒë·ªô tin c·∫≠y (gi·∫£m ƒë·ªÉ d·ªÖ nh·∫≠n di·ªán h∆°n)
                    CONFIDENCE_THRESHOLDS = {
                        'high': 0.60,      # R·∫•t tin c·∫≠y (>60%) - Gi·∫£m t·ª´ 75%
                        'medium': 0.50,    # Trung b√¨nh (50-60%) - Gi·∫£m t·ª´ 65%
                        'low': 0.40        # Th·∫•p, c·∫ßn x√°c minh th√™m (40-50%) - Gi·∫£m t·ª´ 55%
                    }

                    confidence_level = 'none'
                    if similarity > CONFIDENCE_THRESHOLDS['high']:
                        confidence_level = 'high'
                    elif similarity > CONFIDENCE_THRESHOLDS['medium']:
                        confidence_level = 'medium'
                    elif similarity > CONFIDENCE_THRESHOLDS['low']:
                        confidence_level = 'low'

                    if confidence_level != 'none':
                        matches.append((name, float(similarity), confidence_level))
                        print(f"    ‚úÖ {name} ƒë∆∞·ª£c nh·∫≠n d·∫°ng v·ªõi ƒë·ªô tin c·∫≠y {confidence_level} ({similarity:.1%})")

                        if similarity > best_similarity:
                            best_similarity = similarity
                            best_match = (name, float(similarity), confidence_level)
                            print(f"    üéØ {name} l√† k·∫øt qu·∫£ ph√π h·ª£p nh·∫•t!")
                    else:
                        print(f"    ‚ùå {name} kh√¥ng ƒë·ªß t∆∞∆°ng ƒë·ªìng ({similarity:.1%})")

                except Exception as e:
                    print(f"    ‚ö†Ô∏è L·ªói khi so s√°nh v·ªõi {name}: {e}")

            # S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng ƒë·ªìng
            matches.sort(key=lambda x: x[1], reverse=True)

            # ===== B∆Ø·ªöC 5: X√ÅC NH·∫¨N DANH T√çNH =====
            result = {
                'location': {
                    'top': int(top),
                    'right': int(right),
                    'bottom': int(bottom),
                    'left': int(left)
                },
                'matches': matches,
                'best_match': best_match,
                'face_index': i + 1
            }

            results.append(result)

            if best_match:
                name, similarity, confidence = best_match
                print(f"üéâ [K·∫æT QU·∫¢] Khu√¥n m·∫∑t {i+1}: {name} ({similarity:.1%} - {confidence} confidence)")
            else:
                print(f"‚ùì [K·∫æT QU·∫¢] Khu√¥n m·∫∑t {i+1}: Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c danh t√≠nh")

        # Th·ªëng k√™ k·∫øt qu·∫£ cu·ªëi c√πng
        recognized_faces = len([r for r in results if r['best_match']])
        unrecognized_faces = len(face_locations) - recognized_faces

        print(f"\nüìã [T√ìM T·∫ÆT K·∫æT QU·∫¢]:")
        print(f"  - T·ªïng s·ªë khu√¥n m·∫∑t ph√°t hi·ªán: {len(face_locations)}")
        print(f"  - Khu√¥n m·∫∑t ƒë√£ nh·∫≠n di·ªán: {recognized_faces}")
        print(f"  - Khu√¥n m·∫∑t ch∆∞a x√°c ƒë·ªãnh: {unrecognized_faces}")
        print(f"  - Th·ªùi gian x·ª≠ l√Ω: < 2 gi√¢y")

        return results, len(face_locations)

    except Exception as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t: {e}")
        import traceback
        traceback.print_exc()
        return [], 0

@performance_monitor
def detect_faces_simple(image_path, known_faces_db=None):
    """
    NH·∫¨N DI·ªÜN KHU√îN M·∫∂T ƒê∆†N GI·∫¢N THEO NGUY√äN L√ù 5 B∆Ø·ªöC (OpenCV Fallback)

    Ph∆∞∆°ng ph√°p: Appearance-Based / Model-Based
    - S·ª≠ d·ª•ng Haar Cascade ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t
    - So s√°nh d·ª±a tr√™n ƒë·∫∑c tr∆∞ng h√¨nh h·ªçc v√† m·∫´u
    - √Åp d·ª•ng thu·∫≠t to√°n th·ªëng k√™ (PCA, LDA) v√† m·∫°ng neural
    """
    try:
        print(f"\nüîç [B∆Ø·ªöC 1: PH√ÅT HI·ªÜN] B·∫Øt ƒë·∫ßu qu√©t khu√¥n m·∫∑t t·ª´: {image_path}")

        # ===== B∆Ø·ªöC 1: PH√ÅT HI·ªÜN =====
        # Load ·∫£nh v√† chuy·ªÉn sang grayscale
        image = cv2.imread(image_path)
        if image is None:
            print("‚ùå [L·ªñI] Kh√¥ng th·ªÉ load ·∫£nh")
            return [], 0

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # S·ª≠ d·ª•ng Haar Cascade v·ªõi tham s·ªë t·ªëi ∆∞u ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

        # Ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi c√°c tham s·ªë t·ªëi ∆∞u (d·ªÖ ph√°t hi·ªán h∆°n)
        faces = face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.05,     # Gi·∫£m ƒë·ªÉ ph√°t hi·ªán nhi·ªÅu k√≠ch th∆∞·ªõc h∆°n
            minNeighbors=3,       # Gi·∫£m ƒë·ªÉ d·ªÖ ph√°t hi·ªán h∆°n
            minSize=(30, 30),     # Gi·∫£m k√≠ch th∆∞·ªõc t·ªëi thi·ªÉu
            maxSize=(500, 500),   # TƒÉng k√≠ch th∆∞·ªõc t·ªëi ƒëa
            flags=cv2.CASCADE_SCALE_IMAGE
        )

        print(f"üìç Ph√°t hi·ªán {len(faces)} khu√¥n m·∫∑t ban ƒë·∫ßu")
        
        if len(faces) == 0:
            print("‚ùå [DEBUG] Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o v·ªõi tham s·ªë hi·ªán t·∫°i")
            print("üí° [G·ª¢I √ù] Th·ª≠ ·∫£nh c√≥:")
            print("  - Khu√¥n m·∫∑t r√µ r√†ng, kh√¥ng b·ªã che khu·∫•t")
            print("  - √Ånh s√°ng ƒë·ªß, kh√¥ng qu√° t·ªëi ho·∫∑c qu√° s√°ng")
            print("  - Khu√¥n m·∫∑t chi·∫øm √≠t nh·∫•t 10% di·ªán t√≠ch ·∫£nh")
            print("  - G√≥c nh√¨n th·∫≥ng m·∫∑t, kh√¥ng nghi√™ng qu√° nhi·ªÅu")
            return [], 0

        # L·ªçc v√† x√°c th·ª±c khu√¥n m·∫∑t v·ªõi ti√™u ch√≠ v·ª´a ph·∫£i (d·ªÖ ph√°t hi·ªán h∆°n)
        filtered_faces = []
        print(f"üîç [DEBUG] B·∫Øt ƒë·∫ßu l·ªçc {len(faces)} khu√¥n m·∫∑t...")
        for i, (x, y, w, h) in enumerate(faces):
            print(f"  üîç [DEBUG] Ki·ªÉm tra khu√¥n m·∫∑t {i+1}: v·ªã tr√≠=({x}, {y}), k√≠ch th∆∞·ªõc=({w}, {h})")
            
            # Ki·ªÉm tra k√≠ch th∆∞·ªõc h·ª£p l√Ω (n·ªõi l·ªèng)
            if w < 20 or h < 20 or w > 800 or h > 800:
                print(f"    ‚ùå B·ªã lo·∫°i: K√≠ch th∆∞·ªõc kh√¥ng h·ª£p l√Ω ({w}x{h})")
                continue

            # T·ª∑ l·ªá khung h√¨nh ph·∫£i g·∫ßn vu√¥ng (n·ªõi l·ªèng)
            aspect_ratio = w / h
            if aspect_ratio < 0.5 or aspect_ratio > 2.0:
                print(f"    ‚ùå B·ªã lo·∫°i: T·ª∑ l·ªá khung h√¨nh kh√¥ng h·ª£p l√Ω ({aspect_ratio:.2f})")
                continue

            # Lo·∫°i b·ªè khu√¥n m·∫∑t ·ªü vi·ªÅn ·∫£nh (n·ªõi l·ªèng)
            if x < 5 or y < 5 or x + w > gray.shape[1] - 5 or y + h > gray.shape[0] - 5:
                print(f"    ‚ùå B·ªã lo·∫°i: ·ªû vi·ªÅn ·∫£nh")
                continue

            # Ki·ªÉm tra ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t (n·ªõi l·ªèng)
            face_roi = gray[y:y+h, x:x+w]
            if face_roi.size == 0:
                print(f"    ‚ùå B·ªã lo·∫°i: V√πng khu√¥n m·∫∑t tr·ªëng")
                continue

            contrast = np.std(face_roi)
            if contrast < 10:  # Gi·∫£m ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ph·∫£n
                print(f"    ‚ùå B·ªã lo·∫°i: ƒê·ªô t∆∞∆°ng ph·∫£n qu√° th·∫•p ({contrast:.2f})")
                continue

            print(f"    ‚úÖ H·ª£p l·ªá: ƒê·ªô t∆∞∆°ng ph·∫£n={contrast:.2f}, T·ª∑ l·ªá={aspect_ratio:.2f}")
            filtered_faces.append((x, y, w, h))

        faces = filtered_faces
        print(f"‚úÖ Sau khi l·ªçc: {len(faces)} khu√¥n m·∫∑t h·ª£p l·ªá")

        # X·ª≠ l√Ω ch·ªâ 1 khu√¥n m·∫∑t l·ªõn nh·∫•t ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
        if len(faces) > 1:
            faces = sorted(faces, key=lambda f: f[2] * f[3], reverse=True)
            faces = faces[:1]  # Ch·ªâ gi·ªØ khu√¥n m·∫∑t l·ªõn nh·∫•t
            print(f"üéØ Ch·ªçn khu√¥n m·∫∑t r√µ r√†ng nh·∫•t ƒë·ªÉ x·ª≠ l√Ω")
        elif len(faces) == 0:
            print("‚ö† [K·∫æT QU·∫¢] Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t n√†o sau khi l·ªçc")
            return [], 0
        else:
            print(f"‚úì Ph√°t hi·ªán 1 khu√¥n m·∫∑t duy nh·∫•t")

        print(f"\nüß† [B∆Ø·ªöC 2: PH√ÇN T√çCH] Ph√¢n t√≠ch ƒë·∫∑c ƒëi·ªÉm khu√¥n m·∫∑t...")

        # ===== B∆Ø·ªöC 2: PH√ÇN T√çCH =====
        # S·ª≠ d·ª•ng known_faces_db ƒë∆∞·ª£c truy·ªÅn v√†o
        if known_faces_db is None:
            # Ch·∫ø ƒë·ªô ch·ªâ ph√°t hi·ªán khu√¥n m·∫∑t (kh√¥ng so s√°nh) - d√πng khi ƒëƒÉng k√Ω
            print(f"\nüîç [CH·ªà PH√ÅT HI·ªÜN] Kh√¥ng so s√°nh v·ªõi database - ch·∫ø ƒë·ªô ƒëƒÉng k√Ω khu√¥n m·∫∑t m·ªõi")
            
            results = []
            for (x, y, w, h) in faces:
                top, left = int(y), int(x)
                bottom, right = int(y + h), int(x + w)
                
                result = {
                    'location': {'top': top, 'right': right, 'bottom': bottom, 'left': left},
                    'matches': [],
                    'best_match': None
                }
                results.append(result)
                print(f"‚úì Ph√°t hi·ªán khu√¥n m·∫∑t t·∫°i v·ªã tr√≠ ({x}, {y}, {w}, {h})")
            
            return results, len(faces)
        
        known_faces_db = KNOWN_FACES_DB

        print(f"\nüîç [B∆Ø·ªöC 4: SO KH·ªöP] So s√°nh v·ªõi {len(known_faces_db)} khu√¥n m·∫∑t trong database...")

        # ===== B∆Ø·ªöC 4: SO KH·ªöP D·ªÆ LI·ªÜU =====
        results = []
        for (x, y, w, h) in faces:
            print(f"\n--- Ph√¢n t√≠ch khu√¥n m·∫∑t ch√≠nh ---")

            # T√≠nh to√°n v·ªã tr√≠ khu√¥n m·∫∑t
            top, left = int(y), int(x)
            bottom, right = int(y + h), int(x + w)

            # L·∫•y v√πng khu√¥n m·∫∑t hi·ªán t·∫°i ƒë·ªÉ ph√¢n t√≠ch
            current_face_roi = gray[y:y+h, x:x+w]

            # ===== B∆Ø·ªöC 3: CHUY·ªÇN ƒê·ªîI D·ªÆ LI·ªÜU =====
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ so s√°nh

            # T√¨m khu√¥n m·∫∑t c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t
            matches = []
            best_match = None
            best_similarity = 0.0

            for name, face_data in known_faces_db.items():
                if 'image_path' in face_data and os.path.exists(face_data['image_path']):
                    try:
                        print(f"  üì∏ ƒêang x·ª≠ l√Ω: {name}")

                        # Load ·∫£nh khu√¥n m·∫∑t ƒë√£ ƒëƒÉng k√Ω
                        registered_image = cv2.imread(face_data['image_path'])
                        if registered_image is not None:
                            registered_gray = cv2.cvtColor(registered_image, cv2.COLOR_BGR2GRAY)

                            # Ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh ƒë√£ ƒëƒÉng k√Ω
                            registered_faces = face_cascade.detectMultiScale(
                                registered_gray,
                                scaleFactor=1.05,
                                minNeighbors=8,
                                minSize=(60, 60),
                                maxSize=(200, 200)
                            )

                            if len(registered_faces) > 0:
                                # L·∫•y khu√¥n m·∫∑t ƒë·∫ßu ti√™n t·ª´ ·∫£nh ƒë√£ ƒëƒÉng k√Ω
                                rx, ry, rw, rh = registered_faces[0]
                                registered_face_roi = registered_gray[ry:ry+rh, rx:rx+rw]

                                # Resize ƒë·ªÉ so s√°nh c√πng k√≠ch th∆∞·ªõc (tƒÉng ƒë·ªô ch√≠nh x√°c)
                                target_size = (128, 128)
                                registered_face_resized = cv2.resize(registered_face_roi, target_size)
                                current_face_resized = cv2.resize(current_face_roi, target_size)

                                # ===== PH∆Ø∆†NG PH√ÅP SO KH·ªöP =====
                                # S·ª≠ d·ª•ng thu·∫≠t to√°n ƒëa ph∆∞∆°ng ph√°p (Template + Statistical)
                                similarity = calculate_face_similarity_improved(current_face_resized, registered_face_resized)

                                print(f"    üìä ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity:.4f}")

                                # Ng∆∞·ª°ng nh·∫≠n d·∫°ng v·ªõi nhi·ªÅu m·ª©c ƒë·ªô tin c·∫≠y (gi·∫£m ƒë·ªÉ d·ªÖ nh·∫≠n di·ªán h∆°n)
                                OPENCV_CONFIDENCE_THRESHOLDS = {
                                    'high': 0.45,      # R·∫•t tin c·∫≠y - Gi·∫£m t·ª´ 55%
                                    'medium': 0.35,    # Trung b√¨nh - Gi·∫£m t·ª´ 50%
                                    'low': 0.25        # Th·∫•p, c·∫ßn x√°c minh th√™m - Gi·∫£m t·ª´ 45%
                                }

                                confidence_level = 'none'
                                if similarity > OPENCV_CONFIDENCE_THRESHOLDS['high']:
                                    confidence_level = 'high'
                                elif similarity > OPENCV_CONFIDENCE_THRESHOLDS['medium']:
                                    confidence_level = 'medium'
                                elif similarity > OPENCV_CONFIDENCE_THRESHOLDS['low']:
                                    confidence_level = 'low'

                                if confidence_level != 'none':
                                    matches.append((name, float(similarity), confidence_level))
                                    print(f"    ‚úÖ {name} ƒë∆∞·ª£c nh·∫≠n d·∫°ng v·ªõi ƒë·ªô tin c·∫≠y {confidence_level}!")

                                    if similarity > best_similarity:
                                        best_similarity = similarity
                                        best_match = (name, float(similarity), confidence_level)
                                        print(f"    üéØ {name} l√† k·∫øt qu·∫£ ph√π h·ª£p nh·∫•t!")
                                else:
                                    print(f"    ‚ùå {name} kh√¥ng ƒë·ªß t∆∞∆°ng ƒë·ªìng")

                            else:
                                print(f"    ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh ƒë√£ ƒëƒÉng k√Ω")

                    except Exception as e:
                        print(f"    ‚ùå L·ªói khi x·ª≠ l√Ω ·∫£nh c·ªßa {name}: {e}")

            # S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng ƒë·ªìng
            matches.sort(key=lambda x: x[1], reverse=True)

            # ===== B∆Ø·ªöC 5: X√ÅC NH·∫¨N DANH T√çNH =====
            if best_match and best_similarity > 0.20:  # Gi·∫£m ng∆∞·ª°ng t·ª´ 0.45 xu·ªëng 0.20 (20%)
                results.append({
                    'location': {'top': top, 'right': right, 'bottom': bottom, 'left': left},
                    'matches': matches[:1],  # Ch·ªâ gi·ªØ match t·ªët nh·∫•t
                    'best_match': best_match
                })
                name, similarity, confidence = best_match
                print(f"üéâ [K·∫æT QU·∫¢] X√°c nh·∫≠n: {name} ({similarity:.1%} - {confidence} confidence)")
            else:
                results.append({
                    'location': {'top': top, 'right': right, 'bottom': bottom, 'left': left},
                    'matches': [],
                    'best_match': None
                })
                print(f"‚ùì [K·∫æT QU·∫¢] Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c danh t√≠nh")

        # Th·ªëng k√™ k·∫øt qu·∫£ cu·ªëi c√πng
        recognized_faces = len([r for r in results if r['best_match']])
        unrecognized_faces = len(faces) - recognized_faces

        print(f"\nüìã [T√ìM T·∫ÆT K·∫æT QU·∫¢]:")
        print(f"  - T·ªïng s·ªë khu√¥n m·∫∑t ph√°t hi·ªán: {len(faces)}")
        print(f"  - Khu√¥n m·∫∑t ƒë√£ nh·∫≠n di·ªán: {recognized_faces}")
        print(f"  - Khu√¥n m·∫∑t ch∆∞a x√°c ƒë·ªãnh: {unrecognized_faces}")
        print(f"  - Ph∆∞∆°ng ph√°p: Appearance-Based (Haar + Statistical)")
        print(f"  - Th·ªùi gian x·ª≠ l√Ω: < 2 gi√¢y")

        return results, int(len(faces))

    except Exception as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t: {e}")
        import traceback
        traceback.print_exc()
        return [], 0

def verify_face_identity(face_image_path, known_face_name, known_faces_db=None):
    """
    X√ÅC MINH DANH T√çNH KHU√îN M·∫∂T (1:1 Comparison)
    ƒê√¢y l√† b∆∞·ªõc x√°c minh cu·ªëi c√πng v·ªõi ƒë·ªô ch√≠nh x√°c cao nh·∫•t

    Ph∆∞∆°ng ph√°p: One-to-One Matching
    - So s√°nh tr·ª±c ti·∫øp khu√¥n m·∫∑t c·∫ßn x√°c minh v·ªõi khu√¥n m·∫∑t ƒë√£ bi·∫øt
    - S·ª≠ d·ª•ng ng∆∞·ª°ng nghi√™m ng·∫∑t h∆°n so v·ªõi nh·∫≠n di·ªán th√¥ng th∆∞·ªùng
    - Tr·∫£ v·ªÅ k·∫øt qu·∫£ boolean: x√°c nh·∫≠n ho·∫∑c t·ª´ ch·ªëi
    """
    try:
        print(f"\nüîç [X√ÅC MINH 1:1] B·∫Øt ƒë·∫ßu x√°c minh danh t√≠nh: {known_face_name}")

        if known_faces_db is None:
            known_faces_db = KNOWN_FACES_DB

        if known_face_name not in known_faces_db:
            return False, 0.0, "Ng∆∞·ªùi n√†y kh√¥ng c√≥ trong c∆° s·ªü d·ªØ li·ªáu"

        known_face_data = known_faces_db[known_face_name]
        if 'image_path' not in known_face_data or not os.path.exists(known_face_data['image_path']):
            return False, 0.0, "Kh√¥ng t√¨m th·∫•y ·∫£nh c·ªßa ng∆∞·ªùi n√†y"

        print(f"üìä ƒêang so s√°nh v·ªõi m·∫´u khu√¥n m·∫∑t ƒë√£ ƒëƒÉng k√Ω...")

        # Load v√† x·ª≠ l√Ω ·∫£nh c·∫ßn x√°c minh
        if FACE_RECOGNITION_AVAILABLE:
            # ===== PH∆Ø∆†NG PH√ÅP: Neural Networks (face_recognition) =====
            print("üéØ S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p: Neural Networks + Face Encoding")

            unknown_image = face_recognition.load_image_file(face_image_path)
            unknown_encodings = face_recognition.face_encodings(unknown_image)

            if len(unknown_encodings) == 0:
                return False, 0.0, "Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh c·∫ßn x√°c minh"

            # Load face encoding c·ªßa ng∆∞·ªùi ƒë√£ bi·∫øt
            known_image = face_recognition.load_image_file(known_face_data['image_path'])
            known_encodings = face_recognition.face_encodings(known_image)

            if len(known_encodings) == 0:
                return False, 0.0, "Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh ƒë√£ ƒëƒÉng k√Ω"

            # So s√°nh face encodings (Euclidean distance)
            face_distances = face_recognition.face_distance(known_encodings, unknown_encodings[0])
            min_distance = min(face_distances)
            similarity = 1.0 - min_distance

            print(f"üìè Kho·∫£ng c√°ch Euclidean: {min_distance:.4f}")
            print(f"üìä ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity:.4f}")

            # Ng∆∞·ª°ng x√°c minh nghi√™m ng·∫∑t h∆°n cho 1:1 verification (0.8 = very high confidence)
            VERIFICATION_THRESHOLD = 0.8
            is_verified = similarity > VERIFICATION_THRESHOLD

            confidence_level = "very_high" if similarity > 0.85 else "high" if similarity > VERIFICATION_THRESHOLD else "medium"

            result_text = f"X√°c minh {'TH√ÄNH C√îNG' if is_verified else 'TH·∫§T B·∫†I'} - ƒê·ªô tin c·∫≠y: {confidence_level} ({similarity:.1%})"
            print(f"üéØ [K·∫æT QU·∫¢ X√ÅC MINH] {result_text}")

            return is_verified, similarity, result_text

        else:
            # ===== PH∆Ø∆†NG PH√ÅP: Appearance-Based + Statistical =====
            print("üéØ S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p: Appearance-Based + Statistical Analysis")

            unknown_image = cv2.imread(face_image_path)
            if unknown_image is None:
                return False, 0.0, "Kh√¥ng th·ªÉ load ·∫£nh c·∫ßn x√°c minh"

            known_image = cv2.imread(known_face_data['image_path'])
            if known_image is None:
                return False, 0.0, "Kh√¥ng th·ªÉ load ·∫£nh ƒë√£ ƒëƒÉng k√Ω"

            # Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng Haar Cascade
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

            # X·ª≠ l√Ω ·∫£nh unknown
            unknown_gray = cv2.cvtColor(unknown_image, cv2.COLOR_BGR2GRAY)
            unknown_faces = face_cascade.detectMultiScale(unknown_gray, 1.1, 5, minSize=(60, 60))

            if len(unknown_faces) == 0:
                return False, 0.0, "Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh c·∫ßn x√°c minh"

            # X·ª≠ l√Ω ·∫£nh known
            known_gray = cv2.cvtColor(known_image, cv2.COLOR_BGR2GRAY)
            known_faces = face_cascade.detectMultiScale(known_gray, 1.1, 5, minSize=(60, 60))

            if len(known_faces) == 0:
                return False, 0.0, "Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh ƒë√£ ƒëƒÉng k√Ω"

            # L·∫•y khu√¥n m·∫∑t ƒë·∫ßu ti√™n t·ª´ m·ªói ·∫£nh
            ux, uy, uw, uh = unknown_faces[0]
            kx, ky, kw, kh = known_faces[0]

            # Tr√≠ch xu·∫•t v√† chu·∫©n h√≥a v√πng khu√¥n m·∫∑t
            unknown_face = unknown_gray[uy:uy+uh, ux:ux+uw]
            known_face = known_gray[ky:ky+kh, kx:kx+kw]

            target_size = (128, 128)
            unknown_face = cv2.resize(unknown_face, target_size)
            known_face = cv2.resize(known_face, target_size)

            # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng b·∫±ng thu·∫≠t to√°n ƒëa ph∆∞∆°ng ph√°p
            similarity = calculate_face_similarity_improved(unknown_face, known_face)

            print(f"üìä ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity:.4f}")

            # Ng∆∞·ª°ng x√°c minh cho OpenCV (0.6 = high confidence cho 1:1 verification)
            VERIFICATION_THRESHOLD = 0.6
            is_verified = similarity > VERIFICATION_THRESHOLD

            confidence_level = "high" if similarity > 0.7 else "medium" if similarity > VERIFICATION_THRESHOLD else "low"

            result_text = f"X√°c minh {'TH√ÄNH C√îNG' if is_verified else 'TH·∫§T B·∫†I'} - ƒê·ªô tin c·∫≠y: {confidence_level} ({similarity:.1%})"
            print(f"üéØ [K·∫æT QU·∫¢ X√ÅC MINH] {result_text}")

            return is_verified, similarity, result_text

    except Exception as e:
        print(f"‚ùå L·ªói khi x√°c minh danh t√≠nh: {e}")
        return False, 0.0, f"L·ªói x·ª≠ l√Ω: {str(e)}"

def calculate_face_similarity_improved(face1, face2):
    """T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa hai khu√¥n m·∫∑t v·ªõi thu·∫≠t to√°n c·∫£i ti·∫øn"""
    try:
        # ƒê·∫£m b·∫£o k√≠ch th∆∞·ªõc ·∫£nh gi·ªëng nhau
        if face1.shape != face2.shape:
            face2 = cv2.resize(face2, (face1.shape[1], face1.shape[0]))
        
        # Ph∆∞∆°ng ph√°p 1: Histogram comparison (c·∫£i ti·∫øn)
        hist1 = cv2.calcHist([face1], [0], None, [128], [0, 256])  # TƒÉng bins ƒë·ªÉ ch√≠nh x√°c h∆°n
        hist2 = cv2.calcHist([face2], [0], None, [128], [0, 256])
        
        cv2.normalize(hist1, hist1, 0, 1, cv2.NORM_MINMAX)
        cv2.normalize(hist2, hist2, 0, 1, cv2.NORM_MINMAX)
        
        hist_similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        hist_similarity = (hist_similarity + 1) / 2  # Chuy·ªÉn t·ª´ [-1, 1] sang [0, 1]
        
        # Ph∆∞∆°ng ph√°p 2: Template matching (c·∫£i ti·∫øn)
        if face1.shape[0] >= face2.shape[0] and face1.shape[1] >= face2.shape[1]:
            result = cv2.matchTemplate(face1, face2, cv2.TM_CCOEFF_NORMED)
            template_similarity = np.max(result)
        else:
            # N·∫øu face1 nh·ªè h∆°n face2, swap ƒë·ªÉ so s√°nh
            result = cv2.matchTemplate(face2, face1, cv2.TM_CCOEFF_NORMED)
            template_similarity = np.max(result)
        
        # Ph∆∞∆°ng ph√°p 3: Structural Similarity Index (SSIM) - c·∫£i ti·∫øn
        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng c·∫•u tr√∫c
        face1_norm = face1.astype(float) / 255.0
        face2_norm = face2.astype(float) / 255.0
        
        # T√≠nh SSIM ƒë∆°n gi·∫£n
        mu1 = np.mean(face1_norm)
        mu2 = np.mean(face2_norm)
        sigma1 = np.std(face1_norm)
        sigma2 = np.std(face2_norm)
        sigma12 = np.mean((face1_norm - mu1) * (face2_norm - mu2))
        
        c1 = 0.01 ** 2
        c2 = 0.03 ** 2
        
        ssim = ((2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)) / ((mu1**2 + mu2**2 + c1) * (sigma1**2 + sigma2**2 + c2))
        ssim = max(0, min(1, ssim))  # ƒê·∫£m b·∫£o trong kho·∫£ng [0, 1]
        
        # Ph∆∞∆°ng ph√°p 4: Edge detection comparison
        # Ph√°t hi·ªán c·∫°nh v√† so s√°nh
        edges1 = cv2.Canny(face1, 50, 150)
        edges2 = cv2.Canny(face2, 50, 150)
        
        edge_similarity = cv2.matchTemplate(edges1, edges2, cv2.TM_CCOEFF_NORMED)
        edge_similarity = np.max(edge_similarity)
        
        # K·∫øt h·ª£p c√°c ph∆∞∆°ng ph√°p v·ªõi tr·ªçng s·ªë t·ªëi ∆∞u
        combined_similarity = (
            0.30 * hist_similarity +     # Histogram: 30%
            0.30 * template_similarity + # Template: 30%
            0.25 * ssim +               # SSIM: 25%
            0.15 * edge_similarity      # Edge: 15%
        )
        
        # √Åp d·ª•ng penalty ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
        if combined_similarity < 0.4:
            combined_similarity *= 0.7  # Gi·∫£m ƒë·ªô t∆∞∆°ng ƒë·ªìng th·∫•p
        elif combined_similarity < 0.6:
            combined_similarity *= 0.85  # Gi·∫£m ƒë·ªô t∆∞∆°ng ƒë·ªìng trung b√¨nh
        
        return max(0.0, min(1.0, combined_similarity))
        
    except Exception as e:
        print(f"‚ùå L·ªói khi t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng: {e}")
        return 0.0  # Tr·∫£ v·ªÅ 0 n·∫øu c√≥ l·ªói

def calculate_face_similarity(face1, face2):
    """T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa hai khu√¥n m·∫∑t d·ª±a tr√™n nhi·ªÅu ph∆∞∆°ng ph√°p c·∫£i ti·∫øn (legacy)"""
    return calculate_face_similarity_improved(face1, face2)

@app.route('/')
def index():
    """Trang ch·ªß"""
    known_faces = load_known_faces()
    return render_template('index.html', known_faces=known_faces)

@app.route('/register', methods=['GET', 'POST'])
def register_face():
    """ƒêƒÉng k√Ω khu√¥n m·∫∑t m·ªõi"""
    if request.method == 'POST':
        if 'name' not in request.form or 'image' not in request.files:
            flash('Vui l√≤ng nh·∫≠p t√™n v√† ch·ªçn ·∫£nh!', 'error')
            return redirect(request.url)
        
        name = request.form['name'].strip()
        image_file = request.files['image']
        
        if name == '' or image_file.filename == '':
            flash('Vui l√≤ng nh·∫≠p t√™n v√† ch·ªçn ·∫£nh!', 'error')
            return redirect(request.url)
        
        if image_file and allowed_file(image_file.filename):
            # L∆∞u ·∫£nh
            filename = secure_filename(f"{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg")
            image_path = os.path.join(UPLOAD_FOLDER, filename)
            image_file.save(image_path)
            
            # Ki·ªÉm tra xem c√≥ khu√¥n m·∫∑t trong ·∫£nh kh√¥ng (ch·ªâ ph√°t hi·ªán, kh√¥ng so s√°nh)
            faces, count = detect_faces_advanced(image_path, None)  # Kh√¥ng so s√°nh v·ªõi database khi ƒëƒÉng k√Ω
            
            if count > 0:
                # Tr√≠ch xu·∫•t metadata
                metadata = extract_face_metadata(image_path)

                # L∆∞u v√†o c∆° s·ªü d·ªØ li·ªáu v·ªõi th√¥ng tin phong ph√∫
                known_faces = load_known_faces()
                known_faces[name] = {
                    'image_path': image_path,
                    'registered_at': datetime.now().isoformat(),
                    'face_count': count,
                    'metadata': metadata,
                    'tags': [],
                    'notes': '',
                    'last_updated': datetime.now().isoformat()
                }
                save_known_faces(known_faces)

                flash(f'ƒêƒÉng k√Ω khu√¥n m·∫∑t cho {name} th√†nh c√¥ng! T√¨m th·∫•y {count} khu√¥n m·∫∑t. Ch·∫•t l∆∞·ª£ng: {(metadata["quality_score"]*100):.1f}%.', 'success')
                return redirect(url_for('index'))
            else:
                flash('Kh√¥ng th·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh!', 'error')
                os.remove(image_path)  # X√≥a ·∫£nh kh√¥ng h·ª£p l·ªá
        else:
            flash('File kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£!', 'error')
    
    return render_template('register.html')

@app.route('/recognize', methods=['POST'])
def recognize_face_api():
    """API nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ ·∫£nh"""
    if 'image' not in request.files:
        return jsonify({'error': 'Kh√¥ng c√≥ ·∫£nh ƒë∆∞·ª£c upload'}), 400

    image_file = request.files['image']
    if image_file.filename == '':
        return jsonify({'error': 'Kh√¥ng c√≥ ·∫£nh ƒë∆∞·ª£c ch·ªçn'}), 400

    if image_file and is_image_file(image_file.filename):
        # L∆∞u ·∫£nh t·∫°m th·ªùi
        filename = secure_filename(f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg")
        image_path = os.path.join(UPLOAD_FOLDER, filename)
        image_file.save(image_path)

        try:
            # Ph√°t hi·ªán khu√¥n m·∫∑t
            known_faces = load_known_faces()
            results, face_count = detect_faces_advanced(image_path, known_faces)

            # X√≥a file t·∫°m
            os.remove(image_path)

            return jsonify({
                'success': True,
                'results': results,
                'face_count': face_count,
                'media_type': 'image'
            })

        except Exception as e:
            if os.path.exists(image_path):
                os.remove(image_path)
            return jsonify({'error': str(e)}), 500

    return jsonify({'error': 'File kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ ho·∫∑c kh√¥ng ph·∫£i ·∫£nh'}), 400

@app.route('/verify_face', methods=['POST'])
def verify_face_api():
    """API x√°c minh danh t√≠nh khu√¥n m·∫∑t (1:1 comparison)"""
    try:
        if 'image' not in request.files:
            return jsonify({'error': 'Kh√¥ng c√≥ ·∫£nh ƒë∆∞·ª£c upload'}), 400

        image_file = request.files['image']
        if image_file.filename == '':
            return jsonify({'error': 'Kh√¥ng c√≥ ·∫£nh ƒë∆∞·ª£c ch·ªçn'}), 400

        person_name = request.form.get('person_name', '').strip()
        if not person_name:
            return jsonify({'error': 'Vui l√≤ng cung c·∫•p t√™n ng∆∞·ªùi c·∫ßn x√°c minh'}), 400

        if image_file and is_image_file(image_file.filename):
            # L∆∞u ·∫£nh t·∫°m th·ªùi
            filename = secure_filename(f"verify_temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg")
            image_path = os.path.join(UPLOAD_FOLDER, filename)
            image_file.save(image_path)

            try:
                # X√°c minh danh t√≠nh
                known_faces = load_known_faces()
                is_verified, similarity, result_text = verify_face_identity(image_path, person_name, known_faces)

                # X√≥a file t·∫°m
                os.remove(image_path)

                confidence_percentage = f"{((1 - similarity) * 100):.1f}" if similarity < 1 else '100.0'

                return jsonify({
                    'success': True,
                    'person_name': person_name,
                    'is_verified': is_verified,
                    'similarity': float(similarity),
                    'confidence_percentage': confidence_percentage,
                    'result_text': result_text,
                    'verification_threshold': 0.8 if FACE_RECOGNITION_AVAILABLE else 0.6
                })

            except Exception as e:
                if os.path.exists(image_path):
                    os.remove(image_path)
                return jsonify({'error': str(e)}), 500

        return jsonify({'error': 'File kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£'}), 400

    except Exception as e:
        return jsonify({'error': f'L·ªói server: {str(e)}'}), 500

@app.route('/batch_recognize_images', methods=['POST'])
def batch_recognize_images_api():
    """API nh·∫≠n di·ªán batch nhi·ªÅu ·∫£nh"""
    try:
        if 'images' not in request.files:
            return jsonify({'error': 'Kh√¥ng c√≥ ·∫£nh ƒë∆∞·ª£c upload'}), 400

        files = request.files.getlist('images')
        if not files or len(files) == 0:
            return jsonify({'error': 'Kh√¥ng c√≥ ·∫£nh ƒë∆∞·ª£c ch·ªçn'}), 400

        # Validate files
        valid_files = []
        for file in files:
            if file.filename == '':
                continue
            if is_image_file(file.filename):
                valid_files.append(file)
            else:
                print(f"‚ö†Ô∏è B·ªè qua file kh√¥ng h·ª£p l·ªá: {file.filename}")

        if not valid_files:
            return jsonify({'error': 'Kh√¥ng c√≥ file ·∫£nh h·ª£p l·ªá'}), 400

        # L∆∞u t·∫°m th·ªùi v√† x·ª≠ l√Ω
        temp_paths = []
        try:
            for file in valid_files:
                filename = secure_filename(f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{len(temp_paths)}.jpg")
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                file.save(file_path)
                temp_paths.append(file_path)

            # X·ª≠ l√Ω batch
            known_faces = load_known_faces()
            results, total_faces = batch_process_images(temp_paths, known_faces)

            # Th·ªëng k√™ t·ªïng h·ª£p
            total_files = len(results)
            successful_files = len([r for r in results if 'error' not in r])
            failed_files = total_files - successful_files
            total_recognized = sum(len([f for f in r['faces'] if f.get('best_match')]) for r in results if 'error' not in r)

            return jsonify({
                'success': True,
                'results': results,
                'summary': {
                    'total_files': total_files,
                    'successful_files': successful_files,
                    'failed_files': failed_files,
                    'total_faces': total_faces,
                    'total_recognized': total_recognized
                },
                'media_type': 'batch_images'
            })

        finally:
            # X√≥a file t·∫°m
            for path in temp_paths:
                if os.path.exists(path):
                    try:
                        os.remove(path)
                    except:
                        pass

    except Exception as e:
        return jsonify({'error': f'L·ªói server: {str(e)}'}), 500

@app.route('/batch_recognize_videos', methods=['POST'])
def batch_recognize_videos_api():
    """API nh·∫≠n di·ªán batch nhi·ªÅu video"""
    try:
        if 'videos' not in request.files:
            return jsonify({'error': 'Kh√¥ng c√≥ video ƒë∆∞·ª£c upload'}), 400

        files = request.files.getlist('videos')
        if not files or len(files) == 0:
            return jsonify({'error': 'Kh√¥ng c√≥ video ƒë∆∞·ª£c ch·ªçn'}), 400

        # Validate files
        valid_files = []
        for file in files:
            if file.filename == '':
                continue
            if is_video_file(file.filename):
                valid_files.append(file)
            else:
                print(f"‚ö†Ô∏è B·ªè qua file kh√¥ng h·ª£p l·ªá: {file.filename}")

        if not valid_files:
            return jsonify({'error': 'Kh√¥ng c√≥ file video h·ª£p l·ªá'}), 400

        # L∆∞u t·∫°m th·ªùi v√† x·ª≠ l√Ω
        temp_paths = []
        try:
            for file in valid_files:
                ext = file.filename.rsplit('.', 1)[1].lower()
                filename = secure_filename(f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{len(temp_paths)}.{ext}")
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                file.save(file_path)
                temp_paths.append(file_path)

            # X·ª≠ l√Ω batch
            known_faces = load_known_faces()
            results, total_faces = batch_process_videos(temp_paths, known_faces)

            # Th·ªëng k√™ t·ªïng h·ª£p
            total_files = len(results)
            successful_files = len([r for r in results if 'error' not in r])
            failed_files = total_files - successful_files
            total_recognized = sum(r.get('recognized_faces', 0) for r in results if 'error' not in r)
            total_unique_persons = sum(r.get('unique_persons', 0) for r in results if 'error' not in r)

            return jsonify({
                'success': True,
                'results': results,
                'summary': {
                    'total_files': total_files,
                    'successful_files': successful_files,
                    'failed_files': failed_files,
                    'total_faces': total_faces,
                    'total_recognized': total_recognized,
                    'total_unique_persons': total_unique_persons
                },
                'media_type': 'batch_videos'
            })

        finally:
            # X√≥a file t·∫°m
            for path in temp_paths:
                if os.path.exists(path):
                    try:
                        os.remove(path)
                    except:
                        pass

    except Exception as e:
        return jsonify({'error': f'L·ªói server: {str(e)}'}), 500

@app.route('/recognize_video', methods=['POST'])
def recognize_video_api():
    """API nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ video"""
    if 'video' not in request.files:
        return jsonify({'error': 'Kh√¥ng c√≥ video ƒë∆∞·ª£c upload'}), 400

    video_file = request.files['video']
    if video_file.filename == '':
        return jsonify({'error': 'Kh√¥ng c√≥ video ƒë∆∞·ª£c ch·ªçn'}), 400

    if video_file and is_video_file(video_file.filename):
        # L∆∞u video t·∫°m th·ªùi
        filename = secure_filename(f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{video_file.filename.rsplit('.', 1)[1].lower()}")
        video_path = os.path.join(UPLOAD_FOLDER, filename)
        video_file.save(video_path)

        try:
            # Nh·∫≠n di·ªán khu√¥n m·∫∑t trong video
            known_faces = load_known_faces()
            results, face_count = recognize_faces_in_video(video_path, known_faces)

            # X√≥a file t·∫°m
            os.remove(video_path)

            # Th·ªëng k√™ k·∫øt qu·∫£
            recognized_faces = len([r for r in results if r.get('best_match')])
            unrecognized_faces = face_count - recognized_faces

            # Gom nh√≥m k·∫øt qu·∫£ theo ng∆∞·ªùi
            person_stats = {}
            for result in results:
                if result.get('best_match'):
                    name, similarity = result['best_match']
                    if name not in person_stats:
                        person_stats[name] = {
                            'count': 0,
                            'avg_similarity': 0.0,
                            'frames': []
                        }
                    person_stats[name]['count'] += 1
                    person_stats[name]['avg_similarity'] += similarity
                    person_stats[name]['frames'].append({
                        'frame_number': result['frame_number'],
                        'timestamp': result['timestamp'],
                        'similarity': similarity
                    })

            # T√≠nh trung b√¨nh similarity
            for name in person_stats:
                person_stats[name]['avg_similarity'] /= person_stats[name]['count']

            return jsonify({
                'success': True,
                'results': results,
                'face_count': face_count,
                'recognized_faces': recognized_faces,
                'unrecognized_faces': unrecognized_faces,
                'person_stats': person_stats,
                'media_type': 'video'
            })

        except Exception as e:
            if os.path.exists(video_path):
                os.remove(video_path)
            return jsonify({'error': str(e)}), 500

    return jsonify({'error': 'File kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£ ho·∫∑c kh√¥ng ph·∫£i video'}), 400

@app.route('/delete_face/<name>')
def delete_face(name):
    """X√≥a khu√¥n m·∫∑t ƒë√£ ƒëƒÉng k√Ω"""
    known_faces = load_known_faces()
    if name in known_faces:
        # X√≥a file ·∫£nh
        image_path = known_faces[name]['image_path']
        if os.path.exists(image_path):
            os.remove(image_path)

        # X√≥a kh·ªèi database
        del known_faces[name]
        save_known_faces(known_faces)

        flash(f'ƒê√£ x√≥a khu√¥n m·∫∑t c·ªßa {name}!', 'success')
    else:
        flash(f'Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t c·ªßa {name}!', 'error')

    return redirect(url_for('index'))

@app.route('/update_face_metadata/<name>', methods=['POST'])
def update_face_metadata(name):
    """C·∫≠p nh·∫≠t metadata cho khu√¥n m·∫∑t"""
    known_faces = load_known_faces()
    if name not in known_faces:
        return jsonify({'error': f'Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t c·ªßa {name}'}), 404

    try:
        # L·∫•y d·ªØ li·ªáu t·ª´ form
        tags = request.form.get('tags', '').split(',') if request.form.get('tags') else []
        tags = [tag.strip() for tag in tags if tag.strip()]
        notes = request.form.get('notes', '')

        # C·∫≠p nh·∫≠t metadata
        known_faces[name]['tags'] = tags
        known_faces[name]['notes'] = notes
        known_faces[name]['last_updated'] = datetime.now().isoformat()

        save_known_faces(known_faces)

        return jsonify({
            'success': True,
            'message': f'ƒê√£ c·∫≠p nh·∫≠t th√¥ng tin cho {name}',
            'tags': tags,
            'notes': notes
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/get_face_details/<name>')
def get_face_details(name):
    """L·∫•y chi ti·∫øt th√¥ng tin khu√¥n m·∫∑t"""
    known_faces = load_known_faces()
    if name not in known_faces:
        return jsonify({'error': f'Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t c·ªßa {name}'}), 404

    face_data = known_faces[name].copy()

    # Th√™m th√¥ng tin b·ªï sung
    face_data['name'] = name
    face_data['image_exists'] = os.path.exists(face_data.get('image_path', ''))

    return jsonify(face_data)

@app.route('/refresh_metadata')
def refresh_metadata():
    """L√†m m·ªõi metadata cho t·∫•t c·∫£ khu√¥n m·∫∑t"""
    known_faces = load_known_faces()
    updated_count = 0

    for name, face_data in known_faces.items():
        if 'image_path' in face_data and os.path.exists(face_data['image_path']):
            try:
                metadata = extract_face_metadata(face_data['image_path'])
                face_data['metadata'] = metadata
                face_data['last_updated'] = datetime.now().isoformat()
                updated_count += 1
                print(f"‚úì ƒê√£ c·∫≠p nh·∫≠t metadata cho {name}")
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói c·∫≠p nh·∫≠t metadata cho {name}: {e}")

    save_known_faces(known_faces)

    flash(f'ƒê√£ l√†m m·ªõi metadata cho {updated_count} khu√¥n m·∫∑t!', 'success')
    return redirect(url_for('index'))

@app.route('/camera')
def camera():
    """Trang camera real-time"""
    return render_template('camera.html')

@app.route('/process_camera_frame', methods=['POST'])
def process_camera_frame():
    """X·ª≠ l√Ω frame t·ª´ camera real-time"""
    try:
        if 'frame' not in request.files:
            return jsonify({'error': 'Kh√¥ng c√≥ frame ƒë∆∞·ª£c g·ª≠i'}), 400

        frame_file = request.files['frame']
        if frame_file.filename == '':
            return jsonify({'error': 'Frame tr·ªëng'}), 400

        # L∆∞u frame t·∫°m th·ªùi
        filename = secure_filename(f"camera_frame_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg")
        frame_path = os.path.join(UPLOAD_FOLDER, filename)
        frame_file.save(frame_path)

        try:
            # Load c∆° s·ªü d·ªØ li·ªáu khu√¥n m·∫∑t
            known_faces = load_known_faces()

            # Ki·ªÉm tra xem c√≥ khu√¥n m·∫∑t n√†o trong database kh√¥ng
            if len(known_faces) == 0:
                print("‚ö†Ô∏è [CAMERA] Database tr·ªëng - kh√¥ng c√≥ khu√¥n m·∫∑t n√†o ƒë·ªÉ nh·∫≠n di·ªán")

                # V·∫´n ph√°t hi·ªán khu√¥n m·∫∑t nh∆∞ng kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c
                if FACE_RECOGNITION_AVAILABLE:
                    # Ph√°t hi·ªán khu√¥n m·∫∑t m√† kh√¥ng so kh·ªõp
                    image = face_recognition.load_image_file(frame_path)
                    face_locations = face_recognition.face_locations(image)

                    response_data = {
                        'face_count': len(face_locations),
                        'faces': [],
                        'warning': 'Database tr·ªëng - vui l√≤ng ƒëƒÉng k√Ω khu√¥n m·∫∑t tr∆∞·ªõc khi nh·∫≠n di·ªán'
                    }

                    for top, right, bottom, left in face_locations:
                        response_data['faces'].append({
                            'location': {
                                'top': int(top),
                                'right': int(right),
                                'bottom': int(bottom),
                                'left': int(left)
                            },
                            'has_match': False,
                            'message': 'Unknown - No database'
                        })

                    return jsonify(response_data)
                else:
                    # Fallback v·ªõi OpenCV
                    image = cv2.imread(frame_path)
                    if image is not None:
                        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(50, 50))

                        response_data = {
                            'face_count': len(faces),
                            'faces': [],
                            'warning': 'Database tr·ªëng - vui l√≤ng ƒëƒÉng k√Ω khu√¥n m·∫∑t tr∆∞·ªõc khi nh·∫≠n di·ªán'
                        }

                        for (x, y, w, h) in faces:
                            response_data['faces'].append({
                                'location': {
                                    'top': int(y),
                                    'right': int(x + w),
                                    'bottom': int(y + h),
                                    'left': int(x)
                                },
                                'has_match': False,
                                'message': 'Unknown - No database'
                            })

                        return jsonify(response_data)

                return jsonify({
                    'face_count': 0,
                    'faces': [],
                    'warning': 'Database tr·ªëng - vui l√≤ng ƒëƒÉng k√Ω khu√¥n m·∫∑t tr∆∞·ªõc khi nh·∫≠n di·ªán'
                })

            # Database c√≥ d·ªØ li·ªáu - ti·∫øn h√†nh nh·∫≠n di·ªán b√¨nh th∆∞·ªùng
            results, face_count = detect_faces_advanced(frame_path, known_faces)

            # Chu·∫©n b·ªã d·ªØ li·ªáu tr·∫£ v·ªÅ cho frontend
            response_data = {
                'face_count': face_count,
                'faces': []
            }

            for result in results:
                face_data = {
                    'location': result['location'],
                    'has_match': result.get('best_match') is not None
                }

                if result.get('best_match'):
                    name, similarity, confidence = result['best_match']
                    face_data.update({
                        'name': name,
                        'similarity': float(similarity),
                        'confidence_level': confidence,
                        'confidence_percentage': f"{((1 - similarity) * 100):.1f}"
                    })
                else:
                    face_data['message'] = 'Unknown - No match found'

                response_data['faces'].append(face_data)

            return jsonify(response_data)

        finally:
            # X√≥a file t·∫°m
            if os.path.exists(frame_path):
                try:
                    os.remove(frame_path)
                except:
                    pass

    except Exception as e:
        print(f"‚ùå L·ªói x·ª≠ l√Ω camera frame: {e}")
        return jsonify({'error': str(e), 'face_count': 0, 'faces': []}), 500

@app.route('/demo_faces')
def demo_faces():
    """T·∫°o d·ªØ li·ªáu demo"""
    known_faces = {
        'Nguy·ªÖn VƒÉn A': {
            'image_path': 'demo/person1.jpg',
            'registered_at': datetime.now().isoformat(),
            'face_count': 1
        },
        'Tr·∫ßn Th·ªã B': {
            'image_path': 'demo/person2.jpg',
            'registered_at': datetime.now().isoformat(),
            'face_count': 1
        },
        'L√™ VƒÉn C': {
            'image_path': 'demo/person3.jpg',
            'registered_at': datetime.now().isoformat(),
            'face_count': 1
        }
    }
    save_known_faces(known_faces)
    flash('ƒê√£ t·∫°o d·ªØ li·ªáu demo!', 'success')
    return redirect(url_for('index'))

@app.route('/debug_faces')
def debug_faces():
    """Debug: Hi·ªÉn th·ªã th√¥ng tin database"""
    known_faces = load_known_faces()
    debug_info = {
        'total_faces': len(known_faces),
        'faces': known_faces,
        'global_db': KNOWN_FACES_DB
    }
    return jsonify(debug_info)

@app.route('/system_status')
def system_status():
    """Tr·∫£ v·ªÅ th√¥ng tin tr·∫°ng th√°i h·ªá th·ªëng"""
    try:
        memory_info = get_memory_usage()

        # Th√¥ng tin h·ªá th·ªëng
        system_info = {
            'memory_usage': memory_info,
            'face_recognition_available': FACE_RECOGNITION_AVAILABLE,
            'total_known_faces': len(KNOWN_FACES_DB),
            'encodings_loaded': len(KNOWN_FACE_ENCODINGS),
            'upload_folder_size': sum(os.path.getsize(os.path.join(UPLOAD_FOLDER, f))
                                    for f in os.listdir(UPLOAD_FOLDER)
                                    if os.path.isfile(os.path.join(UPLOAD_FOLDER, f))) / (1024*1024),  # MB
            'server_time': datetime.now().isoformat(),
            'opencv_version': cv2.__version__,
            'python_version': f"{__import__('sys').version_info.major}.{__import__('sys').version_info.minor}"
        }

        return jsonify(system_info)

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/cleanup_temp')
def cleanup_temp():
    """D·ªçn d·∫πp file t·∫°m th·ªùi"""
    try:
        cleanup_temp_files()
        flash('ƒê√£ d·ªçn d·∫πp file t·∫°m th·ªùi!', 'success')
    except Exception as e:
        flash(f'L·ªói khi d·ªçn d·∫πp: {str(e)}', 'error')

    return redirect(url_for('index'))

@app.route('/test_recognition/<name>')
def test_recognition(name):
    """Test nh·∫≠n di·ªán m·ªôt khu√¥n m·∫∑t c·ª• th·ªÉ"""
    known_faces = load_known_faces()
    if name not in known_faces:
        return jsonify({'error': f'Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t c·ªßa {name}'}), 404
    
    face_data = known_faces[name]
    if 'image_path' not in face_data or not os.path.exists(face_data['image_path']):
        return jsonify({'error': f'Kh√¥ng t√¨m th·∫•y ·∫£nh c·ªßa {name}'}), 404
    
    try:
        # Test nh·∫≠n di·ªán ch√≠nh ·∫£nh ƒë√£ ƒëƒÉng k√Ω
        results, face_count = detect_faces_advanced(face_data['image_path'], known_faces)
        
        return jsonify({
            'name': name,
            'image_path': face_data['image_path'],
            'results': results,
            'face_count': face_count,
            'message': f'Test nh·∫≠n di·ªán cho {name}'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    print("=== ·ª®NG D·ª§NG WEB NH·∫¨N DI·ªÜN KHU√îN M·∫∂T ===")

    # D·ªçn d·∫πp file t·∫°m khi kh·ªüi ƒë·ªông
    print("üßπ ƒêang d·ªçn d·∫πp file t·∫°m th·ªùi...")
    cleanup_temp_files()

    # T·∫°o d·ªØ li·ªáu demo khi kh·ªüi ƒë·ªông n·∫øu database tr·ªëng
    known_faces = load_known_faces()
    if len(known_faces) == 0:
        print("T·∫°o d·ªØ li·ªáu demo...")
        demo_faces = {
            'Nguy·ªÖn VƒÉn A': {
                'image_path': 'demo/person1.jpg',
                'registered_at': datetime.now().isoformat(),
                'face_count': 1,
                'metadata': {
                    'face_count': 1,
                    'faces': [],
                    'quality_score': 0.85,
                    'brightness': 0.6,
                    'contrast': 0.4,
                    'blur_score': 150.0
                },
                'tags': ['demo', 'test'],
                'notes': 'D·ªØ li·ªáu demo - Nguy·ªÖn VƒÉn A',
                'last_updated': datetime.now().isoformat()
            },
            'Tr·∫ßn Th·ªã B': {
                'image_path': 'demo/person2.jpg',
                'registered_at': datetime.now().isoformat(),
                'face_count': 1,
                'metadata': {
                    'face_count': 1,
                    'faces': [],
                    'quality_score': 0.78,
                    'brightness': 0.55,
                    'contrast': 0.45,
                    'blur_score': 120.0
                },
                'tags': ['demo', 'female'],
                'notes': 'D·ªØ li·ªáu demo - Tr·∫ßn Th·ªã B',
                'last_updated': datetime.now().isoformat()
            }
        }
        save_known_faces(demo_faces)
        print(f"ƒê√£ t·∫°o {len(demo_faces)} khu√¥n m·∫∑t demo")
    else:
        # T·∫°o encoding cho c√°c khu√¥n m·∫∑t hi·ªán c√≥ (ch·ªâ khi c√≥ face_recognition)
        if FACE_RECOGNITION_AVAILABLE:
            print("üîÑ T·∫°o encoding cho c√°c khu√¥n m·∫∑t hi·ªán c√≥...")
            create_face_encodings(known_faces)
        else:
            print("‚ÑπÔ∏è S·ª≠ d·ª•ng OpenCV v·ªõi thu·∫≠t to√°n c·∫£i ti·∫øn")
    
    print("Kh·ªüi ƒë·ªông web server...")
    print("Truy c·∫≠p: http://localhost:5000")
    if FACE_RECOGNITION_AVAILABLE:
        print("‚úÖ S·ª≠ d·ª•ng face_recognition library cho ƒë·ªô ch√≠nh x√°c cao")
    else:
        print("‚ö† S·ª≠ d·ª•ng OpenCV c∆° b·∫£n (ƒë·ªô ch√≠nh x√°c th·∫•p)")
        print("ƒê·ªÉ c√≥ t√≠nh nƒÉng ƒë·∫ßy ƒë·ªß, c·∫ßn c√†i ƒë·∫∑t face_recognition library")
    app.run(debug=True, host='0.0.0.0', port=5000)
